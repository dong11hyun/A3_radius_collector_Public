# 📋 프로젝트 한계점 분석 (Senior Developer Review)

> **검토 일자**: 2026-01-22  
> **검토 대상**: Radius Collector - 편의점 폐업 검증 시스템  
> **검토자 관점**: 상급 개발자 평가

---

## 📌 Executive Summary

이 프로젝트는 카카오맵 API와 공공데이터를 교차 검증하여 편의점 폐업을 탐지하는 **MVP(Minimum Viable Product)** 수준의 구현입니다. 핵심 아이디어(4분면 분할 검색, 3중 교차 검증)는 창의적이지만, **프로덕션 배포에는 다수의 구조적 한계**가 존재합니다.

| 영역 | 현재 수준 | 프로덕션 요구 수준 | 격차 |
|------|----------|------------------|------|
| 보안 | ⚠️ 취약 | 🔒 강화 필요 | 높음 |
| 확장성 | 📊 단일 구 | 🌐 전국 단위 | 높음 |
| 코드 품질 | 📝 MVP | 🏗️ 엔터프라이즈 | 중간 |
| 테스트 커버리지 | ✅ 양호 | 🧪 E2E 필요 | 중간 |
| 운영 안정성 | ⚡ 기본 | 🔄 고가용성 | 높음 |

---

## 🔴 Critical (즉시 개선 필요)

### 1. 보안 취약점

#### 1-1. 하드코딩된 시크릿 키
```python
# config/settings.py:26
SECRET_KEY = "django-insecure-9gg@2u1-zwpbv$7o#a%)#x(d^g7g241v(y54&p6tqi&!n*xygs"
```
- **문제**: Django SECRET_KEY가 코드에 직접 노출됨
- **위험도**: 🔴 Critical (세션 하이재킹, CSRF 우회 가능)
- **해결책**: 환경변수로 분리 (`os.getenv('DJANGO_SECRET_KEY')`)

#### 1-2. 디버그 모드 및 호스트 설정
```python
# config/settings.py:29-31
DEBUG = True
ALLOWED_HOSTS = ['*']
```
- **문제**: 프로덕션에서 DEBUG=True는 스택 트레이스 노출
- **문제**: ALLOWED_HOSTS = ['*']는 Host 헤더 주입 공격에 취약
- **해결책**: 환경별 설정 분리 (django-environ 사용 권장)

#### 1-3. 데이터베이스 비밀번호 노출
```python
# config/settings.py:85
'PASSWORD': 'test1234',
```
- **문제**: DB 비밀번호가 코드에 하드코딩됨
- **해결책**: 환경변수 또는 Secret Manager 사용

---

### 2. 데이터 정합성 문제

#### 2-1. public_data.csv 의존성
```python
# check_store_closure.py:218-225
csv_path = os.path.join(os.path.dirname(__file__), '..', '..', '..', 'public_data.csv')
csv_df = pd.read_csv(csv_path, encoding='cp949')
```
- **문제**: 정적 CSV 파일에 의존 (영등포구 데이터만 포함)
- **문제**: 다른 구에서 실행 시 잘못된 비교 결과 발생
- **해결책**: 구별 CSV 파일 분리 또는 OpenAPI로 동적 수집

#### 2-2. 좌표 비교 정확도 한계
```python
# check_store_closure.py:81-86
def round_coord(val, decimals=4):
    return round(float(val), decimals)
```
- **문제**: 소수점 4자리 반올림 = 약 11m 오차 허용
- **문제**: 밀집 지역에서 다른 매장이 같은 좌표로 판정될 수 있음
- **해결책**: Haversine 거리 계산 또는 PostGIS `ST_DWithin` 활용

---

## 🟠 High Priority (단기 개선 필요)

### 3. 확장성 한계

#### 3-1. 동기식 API 호출
```python
# v2_3_2_collect_Convenience_Only.py:144-152
response = requests.get(url, headers=headers, params=params, timeout=5)
time.sleep(0.2)  # Rate limit 준수
```
- **현재**: 순차적 API 호출 (1개씩)
- **문제**: 25개 구 전체 수집 시 약 **125분** 소요 (25구 × 5분)
- **해결책**: `asyncio` + `aiohttp` 또는 Celery 비동기 태스크

#### 3-2. 메모리 기반 상태 관리
```python
# views.py:319-519
def run_collection_task(target_gu):
    global collection_status
    collection_status = {'status': 'running', ...}
```
- **문제**: 서버 재시작 시 수집 상태 유실
- **문제**: 멀티 워커 환경에서 상태 공유 불가
- **해결책**: Redis 또는 DB 기반 태스크 상태 저장

#### 3-3. 단일 프로세스 실행
```python
# Dockerfile:10
CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]
```
- **문제**: Django 개발 서버는 단일 스레드
- **문제**: 동시 수집 요청 시 블로킹 발생
- **해결책**: Gunicorn/uWSGI + Celery 워커 조합

---

### 4. 외부 API 의존성

#### 4-1. 다이소 비공식 API
```python
# v2_3_1_collect_yeongdeungpo_daiso.py:43
url = "https://fapi.daisomall.co.kr/ms/msg/selStr"
```
- **문제**: 리버스 엔지니어링된 비공식 엔드포인트
- **위험**: API 변경/차단 시 즉시 서비스 중단
- **완화책**: 캐시 레이어 추가, 대체 데이터 소스 확보

#### 4-2. API 에러 핸들링 미흡
```python
# v2_3_2_collect_Convenience_Only.py:153-155
except Exception as e:
    self.stdout.write(self.style.ERROR(f"API 요청 실패: {e}"))
    break
```
- **문제**: 일시적 오류에도 수집 전체가 중단됨
- **해결책**: 지수 백오프 재시도 (tenacity 라이브러리 권장)

---

### 5. 테스트 한계

#### 5-1. 외부 API 모킹 부재
```python
# test_core.py - ScalabilityTests.test_2_boundary_address_validation
# 실제 다이소 API와 카카오 API를 직접 호출
response = requests.post(url, headers=headers, data=json.dumps(payload))
```
- **문제**: 테스트가 외부 API 상태에 의존
- **문제**: CI/CD에서 API 키 없이 실행 불가
- **해결책**: `unittest.mock` 또는 `responses` 라이브러리로 모킹

#### 5-2. E2E 테스트 부재
- **현재**: 단위 테스트 + 통합 테스트만 존재
- **부재**: 전체 파이프라인 (수집 → 검증 → 시각화) E2E 테스트
- **해결책**: Playwright/Selenium 기반 브라우저 테스트 추가

---

## 🟡 Medium Priority (중기 개선)

### 6. 코드 아키텍처

#### 6-1. Fat View 패턴
```python
# views.py - 728 라인, 22개 함수
def run_collection_task(target_gu):
    # 200+ 라인의 수집 로직
```
- **문제**: 비즈니스 로직이 View에 직접 구현됨
- **해결책**: Service Layer 패턴 분리
  - `services/collector.py`
  - `services/validator.py`
  - `services/matcher.py`

#### 6-2. 모델 네이밍 혼란
```python
# models.py
class YeongdeungpoDaiso(models.Model):  # 서울 전체 다이소 저장
    verbose_name = '서울 다이소 (구별)'
    
class YeongdeungpoConvenience(models.Model):  # 서울 전체 편의점 저장
    verbose_name = '서울 편의점 (구별)'
```
- **문제**: 클래스명은 `Yeongdeungpo`지만 실제로는 서울 전체 데이터 저장
- **해결책**: `SeoulDaisoStore`, `SeoulConvenienceStore`로 리네이밍

#### 6-3. DB 테이블명 불일치
```python
class SeoulRestaurantLicense(models.Model):
    class Meta:
        db_table = 'yeongdeungpo_convenience_license'  # 테이블명과 클래스명 불일치
```

---

### 7. 관찰 가능성 (Observability)

#### 7-1. 로깅 미흡
```python
# 현재: stdout 출력만 사용
self.stdout.write(f"✅ [{name}] {action} | 좌표: ({lat:.4f}, {lng:.4f})")
```
- **문제**: 구조화된 로깅 없음
- **문제**: 로그 파일 미저장, 로그 레벨 관리 없음
- **해결책**: Python logging + ELK Stack 또는 CloudWatch

#### 7-2. 메트릭 수집 없음
- **부재**: 요청 지연시간, API 호출 성공률, 에러율 등
- **해결책**: Prometheus + Grafana 또는 Django-silk

---

### 8. 데이터베이스 설계

#### 8-1. 인덱스 최적화 미흡
```python
class StoreClosureResult(models.Model):
    place_id = models.CharField(max_length=50, unique=True)
    gu = models.CharField(max_length=20, default='영등포구')
    # gu 필드에 인덱스 없음 → 구별 쿼리 시 Full Scan
```
- **해결책**: `db_index=True` 또는 복합 인덱스 추가

#### 8-2. 히스토리 관리 없음
- **문제**: 데이터 변경 이력 추적 불가
- **해결책**: django-simple-history 도입

---

## � 추가 한계점 (사용자 지적 사항)

### 9. `run_all.py` 파이프라인 실행 한계

#### 9-1. 블로킹 동기 파이프라인
```python
# run_all.py:71-76
call_command('v2_3_1_collect_yeongdeungpo_daiso', gu=target_gu, clear=True)
# → 다음 단계 실행 전 완전히 종료될 때까지 대기
call_command('v2_3_2_collect_Convenience_Only', gu=target_gu, clear=True)
```
- **문제**: 5단계가 모두 순차 실행 (블로킹)
- **문제**: 중간 단계 실패 시 전체 파이프라인 중단 (`return`)
- **문제**: 부분 재실행 불가 (처음부터 다시 시작해야 함)
- **해결책**: 
  - 체크포인트 기반 재시작 지원
  - 독립적 단계는 병렬 실행 (openapi_1, openapi_2 동시 수집 가능)

#### 9-2. 에러 복구 전략 부재
```python
# run_all.py:74-76
except Exception as e:
    self.stdout.write(self.style.ERROR(f"  ❌ 다이소 수집 실패: {e}"))
    return  # 전체 파이프라인 중단!
```
- **문제**: 한 단계 실패 시 이미 수집한 데이터도 무용지물
- **해결책**: 상태 저장 + 재시도 로직 + 부분 성공 처리

#### 9-3. 병렬 수집 미지원
- **현재**: 1개 구씩 순차 수집
- **문제**: 25개 구 전체 수집 시 `5분 × 25 = 125분` 소요
- **해결책**: Celery 태스크 그룹으로 병렬 수집

---

### 10. `/dev/monitor/` 모니터링 대시보드 한계

#### 10-1. 인증/접근 제어 없음
```python
# views.py:566-576
def dev_monitor_view(request):
    # DEBUG 모드에서만 접근 가능 (선택사항)
    # if not settings.DEBUG:  ← 주석 처리됨!
    #     return HttpResponseForbidden(...)
    return render(request, 'dev_monitor.html', context)
```
- **문제**: 누구나 `/dev/monitor/`에 접근 가능
- **위험**: 시스템 리소스, API 호출 현황 등 민감한 정보 노출
- **해결책**: `@login_required` 또는 IP 화이트리스트

#### 10-2. 폴링 기반 실시간 업데이트
```javascript
// dev_monitor.html:766-774
async function fetchStatus() {
    const response = await fetch('/api/dev-status/');
    // 1초마다 반복 호출
}
```
- **문제**: 1초마다 HTTP 요청 → 서버 부하
- **문제**: 다수 사용자 동시 접속 시 부하 가중
- **해결책**: WebSocket 또는 Server-Sent Events (SSE) 적용

#### 10-3. 메모리 기반 상태 공유
```python
# views.py에서 global 변수로 상태 관리
global collection_status
```
- **문제**: 서버 재시작 시 모니터링 데이터 유실
- **문제**: 멀티 워커 환경에서 상태 불일치
- **해결책**: Redis Pub/Sub 또는 DB 기반 상태 저장

#### 10-4. 924라인 단일 HTML 파일
```html
<!-- dev_monitor.html: 924 라인 -->
<style>/* 460라인의 CSS */</style>
<script>/* 230라인의 JS */</script>
```
- **문제**: 단일 파일에 HTML + CSS + JS 혼재 (유지보수 어려움)
- **해결책**: Vue.js/React 컴포넌트 분리 또는 정적 파일 분리

---

### 11. 지도 표시 (`/store-closure/`) 한계

#### 11-1. 전체 데이터 로딩
```python
# views.py:81
closure_results = StoreClosureResult.objects.all()  # 전체 데이터 조회!
```
- **문제**: 구 필터 없이 모든 데이터 로드
- **문제**: 25개 구 데이터(약 10,000+개) 일괄 렌더링 시 성능 저하
- **해결책**: 구별 필터링 + 페이지네이션 또는 클러스터링

#### 11-2. 중심 좌표 하드코딩
```javascript
// store_closure_map.html:179
center: new kakao.maps.LatLng(37.5171, 126.9066),  // 영등포구청 부근
```
- **문제**: 다른 구 데이터 표시 시에도 영등포구 중심으로 초기화
- **해결책**: 데이터 바운딩박스 기반 동적 중심점 계산

#### 11-3. 마커 렌더링 성능
```javascript
// store_closure_map.html:185-205
stores.forEach(function (store) {
    var marker = new kakao.maps.Marker({...});
    marker.setMap(map);
});
```
- **문제**: 수백 개 마커 개별 생성 → 렌더링 지연
- **해결책**: 마커 클러스터링 API 활용 (`MarkerClusterer`)

#### 11-4. XSS 취약점 가능성
```javascript
// store_closure_map.html:174
var stores = JSON.parse('{{ stores_json|escapejs }}');
```
- **주의**: `escapejs`는 기본 이스케이프만 수행
- **권장**: `json_script` 필터 사용 (Django 2.1+)

---

### 12. 비효율적인 코드 패턴

#### 12-1. N+1 쿼리 패턴
```python
# check_store_closure.py:145-161
for store in kakao_qs:  # N개 반복
    lat = store.location.y  # 매번 객체 접근
```
- **문제**: ORM 쿼리 최적화 없음
- **해결책**: `prefetch_related`, `select_related`, `values()` 활용

#### 12-2. 반복적인 API 키 조회
```python
# 여러 command에서 반복되는 패턴
KAKAO_API_KEY = (
    options.get('api_key') or
    getattr(settings, 'KAKAO_API_KEY', None) or
    os.environ.get('KAKAO_API_KEY', '')
)
```
- **문제**: 같은 로직이 5개 이상 파일에 중복
- **해결책**: 공용 유틸 함수로 추출 (`utils/api_keys.py`)

#### 12-3. 매직 넘버 산재
```python
# v2_3_2_collect_Convenience_Only.py:98-99
DELTA_LAT = 0.0090 * radius_km  # 매직 넘버
DELTA_LNG = 0.0113 * radius_km
```
- **문제**: 상수에 대한 설명/정의 없음
- **해결책**: 상수 클래스 또는 config 파일로 분리

#### 12-4. 비효율적인 집합 연산
```python
# check_store_closure.py:263-265
all_names = restaurant_names | tobacco_names | csv_names
all_addresses = restaurant_addresses | tobacco_addresses | csv_addresses
all_coords = restaurant_coords | tobacco_coords | csv_coords
```
- **문제**: 매 실행마다 3개 데이터소스를 메모리에 로드
- **해결책**: DB 레벨 JOIN 또는 인덱싱, Bloom Filter 활용

#### 12-5. 불필요한 전체 스캔
```python
# v2_3_2_collect_Convenience_Only.py:212-213
wrong_gu_count = sum(1 for c in YeongdeungpoConvenience.objects.all() 
                   if not self.is_target_gu(c.address, target_gu))
```
- **문제**: 전체 데이터를 Python으로 가져와 필터링
- **해결책**: DB 쿼리로 처리 `.exclude(gu=target_gu).count()`

---

## �🟢 Low Priority (장기 개선)

### 9. 개발자 경험 (DX)

- **문서화**: API 명세서 없음 (Swagger/OpenAPI 권장)
- **타입 힌트**: Python 타입 어노테이션 미사용
- **린터**: flake8/black 미적용

### 10. 성능 최적화

- **Bulk Insert**: `update_or_create` 대신 `bulk_create` + `ON CONFLICT`
- **쿼리 최적화**: N+1 문제 점검 필요 (django-debug-toolbar)
- **캐싱**: 반복 조회 데이터 Redis 캐싱

---

## 📊 향후 확장성 로드맵

### Phase 1: 안정화 (1-2주)
- [ ] 보안 취약점 해결 (SECRET_KEY, DEBUG, DB 비밀번호)
- [ ] 환경별 설정 분리 (settings/base.py, production.py)
- [ ] 에러 핸들링 강화 (재시도 로직)

### Phase 2: 확장성 (2-4주)
- [ ] Celery 비동기 태스크 도입
- [ ] Redis 기반 태스크 상태 관리
- [ ] 25개 구 병렬 수집 지원

### Phase 3: 운영 준비 (4-6주)
- [ ] Gunicorn/Nginx 배포
- [ ] CI/CD 파이프라인 (GitHub Actions)
- [ ] 모니터링/알림 시스템 (Sentry, PagerDuty)

### Phase 4: 고도화 (2-3개월)
- [ ] 전국 확장 (서울 외 광역시)
- [ ] 실시간 스트리밍 데이터 수집
- [ ] ML 기반 폐업 예측 모델

---

## 💡 결론

이 프로젝트는 **학습/포트폴리오 프로젝트로는 우수**합니다:
- API 제한 우회 (4분면 분할)
- 교차 검증 아이디어
- PostGIS 활용

그러나 **프로덕션 배포에는 다음이 필수**입니다:
1. 보안 강화 (Critical)
2. 비동기 처리 (확장성)
3. 에러 복구 능력 (안정성)
4. 모니터링 (운영)

> **상급 개발자 코멘트**: 아이디어와 문제 해결 접근 방식은 좋습니다. 다만 "동작하는 코드"에서 "운영 가능한 시스템"으로 가려면 위 한계점들을 체계적으로 해결해야 합니다.
