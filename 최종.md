# Project

## [ 프로젝트 ] Radius Collector: 편의점 폐업 검증 시스템

**일정**: 2025.11 ~ 2026.02

**기술 스택**: Django 5.2, Python 3.x, PostgreSQL + PostGIS, Docker Compose, Kakao Local API, 서울시 OpenAPI

**참여 인원**: 2인 (김동현, 전대원)

**서비스**: 카카오맵 편의점 데이터의 정확성을 공공데이터 3종과 교차 검증하여 폐업 매장을 자동 탐지하는 상권 분석 시스템

---

### 문제 해결 경험

| 문제 | 해결 | 결과 | 도메인 |
|------|------|------|--------|
| 카카오 API 반경 검색 시 최대 45개 제한으로 밀집 지역 데이터 누락 발생 | 다이소 중심점 기준 4분면 분할 검색(Quadrant Search) 알고리즘 설계 | 영등포구 전체 **463개** 편의점 전수 수집, **100% 커버리지** 달성 | 데이터 수집 |
| 카카오 API에서 신규 오픈 매장(다이소 신길점) 검색 불가 | 다이소 공식 웹사이트 네트워크 분석 → 비공식 API 엔드포인트 리버스 엔지니어링 | 신길점 포함 **16개 매장 전수 확보**, 카카오 API 2차 검증으로 좌표 정확도 보완 | 데이터 수집 |
| 서울시 OpenAPI 좌표계(EPSG:5174 TM) ≠ 카카오 좌표계(EPSG:4326 WGS84) 불일치 | `pyproj` 라이브러리로 좌표 변환, 소수점 4자리 반올림 (오차 ~7m) | 이름/주소/좌표 **3중 교차 검증** 구현, 폐업 판별 정확도 **97.6%** | 데이터 정합성 |
| 동시 수집 요청 시 `update_or_create` 중 Race Condition으로 `IntegrityError` 발생 | `select_for_update()` 트랜잭션 락 적용 | 동시성 문제 해결, 데이터 정합성 **100%** 확보 | 동시성 처리 |
| 폐업 결과 조회 시 N+1 쿼리 발생으로 응답 지연 (3초 이상) | `values()` 메서드로 필요한 필드만 조회하도록 최적화 | 쿼리 수 **N+1 → 1개**, 응답 시간 **3초 → 0.1초** (97% 개선) | 성능 최적화 |

---

### 단순 구현 항목

- Django Management Command 기반 5단계 데이터 수집 파이프라인 구축 (`run_all.py`로 원커맨드 실행)
- 서울 25개 구 코드 매핑 및 구별 데이터 저장 지원 (`gu_codes.py`)
- 카카오맵 JS API 기반 결과 시각화 페이지 구현 (정상/폐업 마커 구분)
- 실시간 수집 진행 상황 모니터링 대시보드 개발 (`/dev/monitor/`)
- PostGIS 공간 쿼리 기반 반경 검색 최적화 (100회/0.05초)
- 1,256 라인 핵심 테스트 코드 작성 (ScalabilityTests, E2E, Docker 재현성)

---

### 인프라 경험

- Docker Compose 기반 PostgreSQL + PostGIS 컨테이너 환경 구축
- Django 5.2 + GeoDjango 설정 및 공간 데이터베이스 마이그레이션
- 환경변수 기반 API 키 관리 (.env)

---

### 프로젝트 성과 지표

| 지표 | 수치 |
|------|------|
| 카카오맵 편의점 수집 | 463개 |
| 공공데이터 교차 확인 (정상) | 452개 (97.6%) |
| 폐업 추정 탐지 | 11개 (2.4%) |
| 전체 파이프라인 실행 시간 | 약 5분 / 1개 구 |
| API 호출 최적화 | 약 200회 / 1개 구 |

---

### 기술적 회고

- **데이터 품질 > 도구**: BigQuery + OSM 데이터 시도 → 실제 260개 vs OSM 60개 (75% 누락) → Kakao API 회귀
- **API 한계는 알고리즘으로 극복**: 45개 제한 → Divide & Conquer(4분면 분할)로 전수 조사 달성
- **단일 소스의 한계는 교차 검증으로 보완**: 3가지 공공데이터(휴게음식점 인허가, 담배소매업 인허가, 소상공인 상권정보)로 신뢰도 확보
